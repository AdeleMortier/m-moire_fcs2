\documentclass[french]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{geometry}
\geometry{left=22mm, right=22mm, top=22mm}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{enumitem}   
\usepackage{graphicx}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{csquotes}
\usepackage[style=authoryear,backend=biber]{biblatex}
\usepackage[french]{babel}
\usepackage{hyperref}
\addbibresource{biblio.bib}
\author{Adèle Mortier}
\title{Espace conceptuel: de l'homme à la machine}
\begin{document}
	\maketitle
	\nocite{*}
	\tableofcontents
	\newpage
	\section*{Introduction}
		Il est sans doute séduisant de croire que les concepts ont peu à voir avec le raisonnement, en tant qu'il s'agit d'entités figées, culturellement acquises, et qui somme toute ne posent pas question. Cependant, ce sont bien les concepts qui structurent et rendent possible notre vie mentale; et en particulier, nos raisonnements dépendront des concepts que nous nous sommes donnés.\\
		Loin d'être figés, les concepts sont en fait apparus comme plus mouvants qu'on tendait à le penser : certains éléments semblent appartenir à plusieurs concepts, alors que d'autres, plus \textit{borderline} semblent difficilement catégorisables. Ce sentiment va de pair avec l'idée que chaque concept pourrait être en quelque sorte ``résumé'' par un élément prototypique, qui du même coup dicterait l'appartenance ou non d'autres élément périphériques à ce concept.\\
		Mais paradoxalement, cette incertitude inhérente vis-à-vis des limites des concepts n'empêche des structurations de haut niveau entre les concepts et leurs éléments constitutifs. Les éléments d'un même concept peuvent entretenir entre eux des relations, et ces schémas de relation peuvent être totalement ou partiellement retrouvés au travers de différents concepts. C'est ce que l'on appelle l'analogie entre concepts.\\
		Dans ce mémoire, on se propose de comparer deux approches des concepts : une centrée sur l'humain -- l'approche cognitiviste -- et une plus proche de l'ingénierie -- l'approche statistique. Nous verrons que ces deux approches entretiennent des liens quant à la définition de concept et d'analogie; et nous proposerons des moyens de les confronter.
	\section{Qu'est-ce qu'un concept?}
		Dans cette section nous étudierons comment les domaines de la psychologie et de la philosophie ont abordé la notion de concept au cours de l'histoire. Nous proposerons un approche formelle de ces idées.
		\subsection{L'approche définitoire}
			Il est tentant d'assimiler les concepts psychologiques à des objets mathématiques ou informatiques bien connus: ensembles, catégories, classes:
			\begin{itemize}
				\item un ensemble est analogue à une propriété;
				\item une catégorie est analogue à un ensemble d'objets abstraits liés par des relations;
				\item une classe est analogue à un ensemble d'attributs et de méthodes. 
			\end{itemize}
			De fait, une tradition philosophique née dans l'Antiquité définissait les concepts comme équivalent à un ensemble de conditions nécessaires et suffisantes (\textbf{CNS}). Ces conditions étaient d'appartenance à une classe -- la classe dénotant ce concept:
			\begin{eqnarray*}
			C &\equiv&  \lbrace c_1 \dots c_k \rbrace \\
			C &=& \left\lbrace x \ |\ \bigwedge_{i \in [1, k]}c_i(x)\right\rbrace
			\end{eqnarray*}
			Cette vision des concepts paraissait satisfaisante dans la mesure ou elle répondait à un certain idéal philosophique:
			\begin{itemize}
				\item les concepts formaient des classes homogènes;
				\item leurs frontières étaient bien claires;
				\item ils représentaient ces valeurs fixes, objectives.
			\end{itemize}
			Cela dit, cette approche ne semble pas réellement coïncider avec la réalité des concepts au quotidien. Dans ce qui suit, nous allons passer en revue des approches plus récentes qui relaxent différents paramètres du modèle définitoire.
			\subsection{Continuité des attributs: pour une approche statistique}\label{concept_stat}
				Le modèle définitoire s'appuie sur la notion d'ensemble\footnote{analogue à celle de prédicat}, et la notion concomitante d'appartenance\footnote{analogue à la vérification d'un prédicat dans une logique bivalente avec tiers exclu}. Mais est-ce vraiment ainsi que nous traitons les concepts? Ne peut-on pas ``plus ou moins'' appartenir à un concept?
				\subsubsection{Rigidité du modèle définitoire}
				Le modèle définitoire pourrait également se résumer ainsi: une entité x est un vecteur binaire dont chaque composante correspond à une condition. Une  composante quelconque de x vaut 1 si la condition qui lui correspond est vérifiée par x. Elle vaut 0 si la condition correspondante n'est pas vérifiée.
				\begin{equation*}
				x = \left[\begin{array}{c}
				c_1(x) \\
				\vdots\\
				c_n(x)
				\end{array}\right]
				\end{equation*}
				Dans cette implémentation du modèle définitoire, un concept est une fonction qui prend une entité x est vérifie que les composantes de x correspondant aux CNS du concept sont toutes à 1.
				\begin{eqnarray*}
				C &\equiv&  \lbrace c_{i_1} \dots c_{i_k} \rbrace \\
				C &=& \lambda x. \ \forall j \in [1, k], \ x[i_j] = 1
				\end{eqnarray*}
				Un problème majeur réside dans le caractère binaire des composantes de x. Dans le modèle définitoire, chaque entité vérifie ou ne vérifie pas une condition donnée; il n'y a pas d'entre-deux. Pourtant, \cite{rosch1973} remarque que les attributs des entités du monde varient souvent \textbf{continûment}; il en va ainsi de la couleur et de la forme d'un objet par exemple.
				\begin{figure}[H]
					\centering
					\includegraphics[width=200px]{../images/spectrum.jpg}
					\caption{La couleur se décline sur un spectre, qui correspond à une échelle de longueurs d'onde. Mais cette échelle est continue! Comment définir des ``frontières'' pour la couleur rouge par exemple?}
				\end{figure}			
				\begin{figure}[H]
					\centering
					\includegraphics[width=200px]{../images/homeomorphism.png}
					\caption{En topologie, on définit les homéomorphismes comme des transformations continues et réversibles d'une forme à une autre. Est-on capable de percevoir ces relations de parentés entre les formes? Quand peut-on dire que le donut est devenu une tasse? \href{https://prateekvjoshi.files.wordpress.com/2014/11/3-donut-coffee.png}{source}}
				\end{figure}				
				Certains éléments sont à ``peu près carrés'', d'autres sont ``un peu rouges''; et on peut normalement dire si un élément est ``plus carré'' ou ``plus rouge'' qu'un autre. Tout cela conduit à penser que le vecteur binaire du modèle définitoire devrait être remplacé par un vecteur réel -- ou, en d'autres termes, qu'il faudrait passer d'une logique bivalente à une logique polyvalente.
				\begin{eqnarray*}
				C &\equiv&  \lbrace c_{i_1} \dots c_{i_k} \rbrace \\
				C &=& \lambda x. \ \forall j \in [1, k], \ x[i_j] \geq \theta_j
				\end{eqnarray*}
				Il découle de cette définition que les éléments appartenant à un concept peuvent être sujets à variation. Par exemple, les élément répondant au concept rouge ne sont pas forcément catégoriquement rouge: ils peuvent être rouge-orangé ou rosés. Mais ils doivent tout de même être ``suffisamment'' rouges (d'où la notion de seuil, $\theta_j$). Par exemple, ils ne seront pas bleus ou verts. Les entités, vues comme des vecteurs, sont donc étalées dans un espace relativement restreint qui correspond au concept. Or, si l'on admet que ces entités sont étalées sur un spectre, cela signifie que certaines entités sont plus près du ``gold standard'' que d'autres. Il devient possible d'extraire une entité ``caractéristique'', qui se démarque des autres en tant qu'elle entre le mieux en adéquation avec le concept. \cite{rosch1973} parle à ce sujet de \textbf{prototype} ou d'\textbf{exemplaire}. Une manière de définir cet exemplaire pourrait être:
				\begin{eqnarray*}
				C &\equiv&  \lbrace c_{i_1} \dots c_{i_k} \rbrace \\
				ex(C) &=& argmax_x F(x[i_1], \dots x[i_k]) \\
				&=& argmax_x \sum_{j = 1}^{k}|x[i_j]|^\alpha
				\end{eqnarray*}
				Cet exemplaire pourrait faire office de nouvelle définition du concept. Un concept serait alors l'ensemble des entités suffisamment proches de l'exemplaire, suivant certaines dimensions (ou caractéristiques).
				\begin{eqnarray*}
				x \in C \iff dist(x, ex(C)) \leq \theta_C
				\end{eqnarray*}
				\subsubsection{Confirmation expérimentale}
					La notion de prototype dérivée de l'approche statistique a-t-elle une réalité cognitive? Dans une étude menée sur des populations archaïques ne verbalisant pas ou peu les couleurs et le formes\footnote{ces concepts et leurs sous-concepts étaient donc tout à fait nouveaux pour ces populations}, \cite{rosch1973} montre que les prototypes sont effectivement appris plus facilement, attirent plus l'attention, et son réellement ``attachés'' à un nom de catégorie dans l'esprit des gens.\\
					
					Plus précisément, \cite{rosch1973} montre que les catégories générée par un élément ``focal'' \footnote{c'est-à-dire un élément que nous considérons comme prototypiques d'un concept, par exemple, la couleur rouge, la forme carrée} à l'aide d'une série de transformations, s'apprennent plus facilement et plus rapidement que les catégories ne contenant pas d'élément focal ou celle où l'élément focal n'est pas central (catégories générées à partir d'un élément non focal). De plus, l'élément focal au sein d'une catégorie est appris plus vite et donne lieu à moins d'erreurs, qu'il soit central ou non.\\
					
					Par ailleurs, les participants ont été capables de faire du transfert de connaissances sur un \textit{training set} d'éléments appartenant aux catégories apprises mais jamais rencontrés lors de l'apprentissage. Pour le cas des formes (plus contrôlé que l'expérience mettant en jeu les couleurs), ils ont aussi réussi à identifier les ``bons'' prototypes (les éléments focaux) pour chaque catégorie contenant ledit prototype (\textit{i.e.} les catégories ou le prototype était central et celle où il ne l'était pas).\\
					
					Cette étude confirme l'importance cognitive des prototype et leur caractère structurant. Mais elle pose aussi une question fondamentale: se pourrait-il que l'on ai construit les catégories de notre langage ``autour'' des prototypes, et non pas l'inverse?

			\subsection{Flexibilité des CNS: un ``air de famille''}
				Un problème dual au problème soulevé précédemment réside dans la définition des CNS d'un concept donné. \cite{wittgenstein1953} a par exemple remarqué qu'un concept comme celui de jeu était très difficile à définir par des CNS, car les différentes instances du jeu semblent vérifier des conditions pour le moins contradictoires:
				\begin{itemize}
					\item on pourrait dire que le jeu provoque un sentiment de plaisir (jeu video); pour autant certains jeux évoquent des situations d'affrontement, de compétition (football);
					\item on pourrait dire que le jeu nécessite de l'adresse (tennis de table) ou de la stratégie (go); pour autant certains jeux sont entièrement régis par le hasard (échelles et serpents).
				\end{itemize}
				Les différents types de jeu ne semblent donc pas pouvoir vérifier \textit{ensemble} les mêmes contraintes. Malgré cela, le concept de jeu nous semble très \textbf{naturel} et nous sommes capables de classifier des activités nouvelles comme des jeux sans trop de problèmes\footnote{par exemple, lorsque la mode du sudoku est arrivée en France, ou lorsqu' un nouveau jeu apparaît dans les cours d'école!}. \cite{pigliucci2003} fait la même remarque concernant le concept d'espèce qui fait débat en biologie : ``it is impossible to define species, but it is certainly feasible to recognize them when you see them''.\\
				
				Par ailleurs, \cite{rosch1975} relèvent qu'une évidente absence d'homogénéité des concepts (comme le concept de meuble, de véhicule, de légume...) ne choque pas fondamentalement les sujets et que ceux-ci continuent à croire, malgré l'évidence, que les concepts ont des propriétés générales vérifiées par toutes leurs instances.\\
				
				Pour résoudre ce problème, Wittgenstein introduit la notion d'``\textbf{air de famille}''. Pour que deux entités soient liées entre elles et se réduisent à un même concept, il faut qu'elles partagent un certain nombre de traits en commun. Mais, contrairement au modèle définitoire, très strict, ces traits communs ne sont pas forcément tout à fait fixés; il doivent juste être en nombre suffisant. Pour en revenir à notre interprétation vectorielle du modèle définitoire, la notion d'air de famille se traduit par une relaxation du quantificateur $\forall$. Par exemple, on pourrait penser à la formulation alternative suivante:
				\begin{eqnarray*}
				C &\equiv&  \lbrace c_{i_1} \dots c_{i_k} \rbrace \\
				C &=& \lambda x. \ |\lbrace j | x[i_j] = 1 \rbrace| > |\lbrace j | x[i_j] = 0 \rbrace|
				\end{eqnarray*}
				Les éléments d'un concepts seraient les éléments vérifiant une majorité d'attributs liés au concept. Ou, inversement, un concept serait défini par les attributs fréquemment représentés au sein des membres de ce concept, et peu fréquemment représenté en dehors du concept (\cite{rosch1975}). Cette dernière définition contribue à inverser le paradigme, en tant qu'elle dérive le concept des éléments qui lui appartiennent, et non plus l'inverse.\\
				
				Mais que dire alors de la notion de prototype introduite précédemment? Un prototype devrait vérifier un maximum de conditions liées au concept; par maximum, on entend pas forcément toutes le conditions (ce serait le cas idéal), mais plus de conditions que n'importe quel autre entité appartenant au concept. Si l'on trace un diagramme de Venn correspondant aux attributs du concept, le prototype doit se trouver dans le secteur correspondant au maximum d'intersections.
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
				\begin{scope}[blend group = soft light]
				\fill[red!30!white]   ( 90:1.2) circle (2);
				\fill[green!30!white] (210:1.2) circle (2);
				\fill[blue!30!white]  (330:1.2) circle (2);
				\end{scope}
				\node at ( 90:2)    {$c_1$};
				\node at ( 210:2)   {$c_2$};
				\node at ( 330:2)   {$c_3$};
				\node [font=\Large] {Prototype};
				\end{tikzpicture}
				\end{figure}
				\cite{rosch1975} valident expérimentalement cette hypothèse et montrent que les éléments considérés comme prototypiques d'un concept sont les éléments partageant le plus d'attributs avec les autres éléments du concept\footnote{dit autrement, la notion de centralité adéquate serait une centralité de degré en théorie des graphes, sur un graphe dont les sommets sont les entités, et dont les arêtes pondérées définissent une relation de partage d'attributs entre entités...cette représentation semble extrêmement intuitive}:
				\begin{equation*}
				c(x) = \sum_{i = 1}^{k}c_i(x)\sum_{x' \neq x \in C}c_i(x') = \sum_{c| c(x)}|c\cap C|-1
				\end{equation*}
				Cela dit, cette notion est insuffisante à définir un critère de ``bon prototype''. En effet, les prototypes très généraux partageant beaucoup d'attributs avec les entités de leur concept, mais aussi beaucoup d'attributs avec des entités hors de leur concept, sont susceptibles d'être considérés comme ``bons''. C'est pourquoi \cite{rosch1975} mettent en avant la nécessité d'un \textit{tradeoff} entre un air de famille interne au concept et une absence d'air de famille externe au concept. Le prototype doit être \textbf{général} tout en étant \textbf{distinctif}. Ce \textit{tradeoff} pourrait être modélisé par la notion de centralité suivante:
				\begin{equation*}
				c(x) = \sum_{i = 1}^{k}c_i(x)\sum_{x' \neq x}\mathds{1}_{\lbrace x' \in C \rbrace}c_i(x') - \mathds{1}_{\lbrace x' \notin C \rbrace}c_i(x') = \sum_{c| c(x)}|c\cap C| - |c \cap \complement C|
				\end{equation*}
			\subsection{Interdépendance des concepts entre eux: pour une ``théorie des théories''}
				Un des écueils des deux théories précédentes est de considérer que nous construisons les différents concepts du monde indépendamment les uns des autres. Pourtant, force est de constater que les concepts interagissent entre eux -- ou du moins c'est ainsi que nous le percevons. Ils forment par exemple une hiérarchie (un arbre), selon leur degré de spécificité.
				\begin{itemize}
					\item les concepts les plus élevés dans la hiérarchie sont les plus abstraits, et sont appelés \textbf{superordinaux}.
					\item les concepts les plus bas sont très spécifiques et sont appelés \textbf{subordinaux}.
					\item les concepts ``relativement au milieu'' sont ceux que nous sommes les plus prompts à utiliser, ils sont parfois appelés ``basiques''.
				\end{itemize}
				Ainsi, quand nous apprenons un concept superordinal, nous utilisons sans doute les concepts subordinaux ou basiques qui le composent et que nous avons déjà rencontrés. L'apprentissage de la \textbf{causalité} entre concepts est un autre exemple d'apprentissage conjoint des concepts.\\
				
				La théorie des théories (\textit{theory-theory}) a été développée en réaction aux deux précédentes approches (approche définitoire et approche par prototypes avec ``air de famille'') en partant de ce constat. Elle s'inspire des travaux de Piaget ayant trait au constructivisme. Cette théorie postule en effet que les humains construisent des modèles (``théories'') scientifiques du monde qui les entoure (\cite{gopnik2012}). Ainsi, les enfants sont capables très tôt de développer un modèle plus ou moins naïf de la psychologie de l'autre\footnote{cela est à comparer avec la théorie de l'esprit}, mais aussi, pour ce qui nous intéresse, ils mettent en place un modèle d'interaction des concepts rencontrés. Lorsqu'ils sont confrontés à de nouvelles preuves, les humains sont susceptibles de revoir leur théorie. Ainsi, la théorie des théories a été récemment mise en relation avec les approches bayésiennes de l'apprentissage (\cite{gopnik2012}); ce qui fait également le lien avec l'apprentissage statistique que nous étudierons dans la section suivante.\\
				
				Les théories sont caractérisées par leur \textbf{structure}, leur \textbf{fonction} et leur \textbf{dynamique}. La structure d'une théorie met en jeu des représentations du monde à la fois cohérentes, abstraites et causales. La fonction d'une théorie est de prévoir ce qui va se passer ou pourrait se passer, et d'interpréter les preuves à disposition.
				Mais surtout, les théories ont une dynamique, basée sur l'idée de ``mise à jour rationnelle'' en fonction des données disponibles. Cette dynamique est notamment capable d'expliquer certaines erreurs de catégorisation ``raisonnables'' que nous sommes parfois tentés de faire. Par exemple, on peut être tenté de dire qu'une baleine est un poisson, car la catégorie des mammifères marins, comme celle des poissons, vit dans l'eau. De plus, les mammifères marins ont des caractères externes qui les font ``ressembler'' aux poissons (nageoires, queue). L'amalgame, mis en perspective avec notre idée du monde et notre manière de mettre en place des théories scientifiques naïves, n'apparaît plus si absurde. Et nous pouvons le mettre en échec une fois que nous avons accumulé les preuves suffisantes.
		
		\section{Qu'est-ce qu'une analogie?}
			L'analogie est une notion intimement liée à celle de concept, car elle concerne la \textit{conservation} des concepts entre différents scénarios.
			\subsection{Définition formelle}
			L'analogie est une opération d'ordre supérieur sur les concepts abstraits; par exemple, le concept de \textit{procrastination} ou d'\textit{excuse}. Une analogie peut être vue comme une fonction d'une situation, problème, scénario vers un autre.
			Le modèle n'analogie le plus simple date d'Aristote; c'est ce que l'on appelle l'analogie à 4 termes, ou l'\textbf{analogie proportionnelle} (\cite{holyoak2012}):
			\begin{equation*}
			a:b::c:d
			\end{equation*}
			Ce qui se lit : $a$ est à $b$ ce que $c$ est à $d$. Par exemple:
			\begin{enumerate}[label=(\roman*)]
				\item ``le pied est à la chaussure ce que la main est au gant'' [analogie sémantique];
				\item ``le roi est à l’État ce que Dieu est au cosmos'' [analogie sémantique];
				\item ``journaliste est à journal ce que guitariste est à guitare'' [analogie sémantique/morphologique];
				\item ``dansait est à danser ce que jouait est à jouer'' [analogie morphologique];
			\end{enumerate}
			Dans ce cadre très simple, deux éléments ($a$ et $b$) entretiennent la même relation que deux autres éléments ($c$ et $d$). Par exemple dans (i), la relation est une relation de partie du corps à vêtement; dans (ii), c'est une relation de pouvoir, dans (iii), c'est une relation de métier à objet de travail; dans (iv), c'est une relation de temps. À partir de cet exemple, on peut définir une analogie comme une fonction $\Phi$\footnote{si l'on considère les concepts comme des \textit{catégories} mathématiques, une analogie entre concepts peut naturellement être vue comme un foncteur...}:
			\begin{itemize}
				\item de concepts à concepts;
				\item de relations entre concepts à relations entre concepts;
			\end{itemize}
			Avec la contrainte que, si une relation R lie $a$ et $b$, alors $\Phi(R)$ lie $\Phi(a)$ et $\Phi(b)$ (``conservation des flèches''). Il est important de noter que cette définition s'étend à des problèmes de taille arbitraire, faisant intervenir un grand nombre d'objets qui interagissent entre eux. \\
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
			\matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
			{
				chaussure & gant \\
				pied & main \\};
			\path[-stealth]
			(m-1-1) edge node [left] {habille} (m-2-1)
			edge node [below] {$\Phi$} (m-1-2)
			(m-2-1.east|-m-2-2) edge node [below] {$\Phi$} (m-2-2)
			(m-1-2) edge node [right] {habille} (m-2-2);
			\end{tikzpicture}
			\begin{tikzpicture}
			\matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
			{
				planète & électron \\
				soleil & noyau \\};
			\path[-stealth]
			(m-1-1) edge node [left] {orbite} (m-2-1)
			edge node [below] {$\Phi$} (m-1-2)
			(m-2-1.east|-m-2-2) edge node [below] {$\Phi$} (m-2-2)
			(m-1-2) edge node [right] {orbite} (m-2-2);
			\end{tikzpicture}
			\caption{Représentation en diagramme des analogies entre concepts vues précédemment (analogies de structure)}
			\end{figure}
			On pourra alors définir:
			\begin{itemize}
				\item une analogie de \textbf{structure} comme une fonction $\Phi$ égale à l'identité sur l'espace des relations entre concepts ($\Phi(R) = R$);
				\item une analogie de \textbf{surface} comme une fonction $\Phi$ égale à l'identité sur l'espace des concepts (ou tout au moins, un sous-espace saillant des concepts).
			\end{itemize}
		\begin{table}[H]
			\begin{tabular}{c|c|c}
				& même structure $\downarrow$ & \\ \hline
				même surface $\rightarrow$ & reporter un rdv chez le médecin & prendre un rdv chez le médecin\\ \hline
				& reporter l'envoi d'un mail & 
			\end{tabular}
			\caption{Exemples d'analogies de surface et de structure dérivées à partir d'une même situation}
		\end{table}
			Les analogies de structure sont souvent assimilées aux analogies \textit{stricto sensu} (\cite{holyoak2012}). Elles sont de fait les plus abstraites et sans doute les plus intéressantes, car elles permettent de transposer des situations familières sur des situations inédites (\cite{gentner1997}). Les analogies de structure sont donc très utiles à la résolution de problèmes, mais aussi à l'apprentissage de catégories abstraites (\textbf{schémas}): si on parvient à établir un lien entre deux situations ayant la même structure, on en apprend davantage sur la structure elle-même (\cite{gentner1997,holyoak2012}). Cela dit, les analogies structurelles ne sont pas toujours très évidentes, car au delà des analogies de premier ordre dont on a parlé (conservation de relations entre objets différents), il existe des analogies de second ordre, qui s'appliquent cette fois sur des relations. 
		\subsection{Analogies et concepts}
			Puisque l'analogie peut être comprise comme un \textit{mapping} de concept à concept, certains auteurs (\cite{lakoff1980}) vont jusqu'à penser que les ``concepts'' de notre vie quotidienne \textit{résultent} en fait d'une analogie avec des concepts ``fondamentaux'', comme l'orientation (haut/bas), le mouvement dans l'espace, l'être (entité/substance). L'analogie est alors appelée ``métaphore conceptuelle'', car elle demeure implicite à nos yeux et met en relation deux mondes distants sémantiquement (\cite{holyoak2012}); mais d'un autre côté elle est aussi très ancrée dans notre expérience des choses\footnote{des liens avec la cognition incarnée et la théorie de l'évolution peuvent notamment être mis en évidence}. Pour \cite{lakoff1980}, les concepts\footnote{le terme de \textit{gestalt} est aussi régulièrement utilisé par ces auteurs} que nous pensons utiliser comme tels sont en fait entièrement appréhendés à partir d'autres concepts. Nous ne sommes pas ici dans un problème simplement linguistique (homonymie); l'identification d'une chose à une autre s'exprime par les mots, mais dépasse les mots pour toucher les concepts sous-jacents. Dans certains cas cette identification se rapproche plus d'un \textit{mélange} que d'un \textit{mapping} (\cite{holyoak2012}).\\
			
			L'exemple le plus fameux illustrant cette théorie est la métaphore structurelle \textit{argument is war}: lorsque nous évoquons un débat argumenté, nous utilisons sans nous en apercevoir un grand nombre de mots et de collocations liés au concept de guerre; par exemple en français, ``camper sur ses  positions'', ``défendre un point de vue'', ``adopter une stratégie argumentative'' etc.  Ce point de vue pose l'analogie comme un précurseur des concepts, et remet donc du même coup en question l'idée de concept; mais cela ne fait pas l'unanimité. Comme le souligne \cite{holyoak2012}, il est probable que les métaphores familières soient interprétées comme des schémas à part entière (tâche de catégorisation) -- et que les métaphores inédites soient traitées comme des cas propres d'analogie.
		\subsection{D'un point de vue cognitif}\label{analogy_cog}
		D'un point de vue plus pragmatique, deux problèmes analogues en structure auront le même schéma de résolution. En revanche, deux problèmes simplement analogues en surface ont des schémas de résolution différents. C'est donc l'analogie de structure qui est seule susceptible d'aider à la résolution de problèmes nouveaux, par transposition d'un problème déjà rencontré. Plus précisément, le raisonnement analogique se déroule en cinq phases principales (\cite{gentner1997,holyoak2012}):
		\begin{center}
			\begin{minipage}{.6\textwidth}
			\begin{enumerate}
			\item prise de connaissance du problème cible;
			\item revue des analogues pertinents présents en mémoire;
			\item choix\footnote{on parle ici de choix, mais cette étape est en fait très conditionnée par le \textit{priming}} d'un problème source parmi ces analogues;
			\item mise en relation du problème source et du problème cible;
			\item résolution des parties manquantes du problème cible (inférence).
		\end{enumerate}
		\end{minipage}\qquad
		\begin{minipage}{.3\textwidth}
				\begin{figure}[H]
			\centering
			\includegraphics[width=\textwidth]{../images/analogy_cog.png}
			\caption{La résolution de problème comme tâche de \textit{pattern matching}}
		\end{figure}
		\end{minipage}
		\end{center}
		Suivant cette approche, une analogie pertinente est une analogie avec un fort degré de \textbf{parallélisme} dans les relations entre objets, et un haut niveau de \textbf{systématicité} -- autrement dit une préférence pour des systèmes fortement connexes et hiérarchisés par des relations d'ordre supérieur (\cite{gentner1997, holyoak2012}).\\
		
		Il a été montré que certaines transpositions de problèmes sont plus faciles que d'autres. Dans un cadre expérimental, des sujet confrontés à deux problèmes auront du mal à déceler des analogies de structure; et de même lorsqu'on leur demande expressément de faire des analogies à partir d'une situation donnée, ils produisent plus fréquemment des analogies de surface. Cependant, \cite{raynal2018}, par un nouveau paradigme de remémoration libre, montrent que les sujets sont capables de générer des analogies de structure lorsqu'ils sont libres de convoquer des domaines familiers. Plus précisément, les analogies structurelles sont globalement plus fréquentes, et les individus faisant une majorité d'analogies structurelles sont majoritaires. Les exemples utilisés s'appuyaient sur les concepts très courants (excuse, procrastination). La capacité à transposer un problème dépend donc en partie des champs sémantiques des objets, et de la disponibilité en mémoire:
		\begin{itemize}
			\item il est plus facile de transposer vers un domaine plus familier (e.g. lorsque l'on peut utiliser ses propres expériences);
			\item il est plus facile de transposer entre deux domaines proches (par exemple, entre l'orbite Terre/Soleil et l'orbite Lune/Terre, mais pas entre l'orbite Terre/Soleil et l'orbite Électron/Noyau).
		\end{itemize}		
		Cela est peut être du au fait que les éléments familiers et les relations qu'ils entretiennent entre eux activent de façon répétitive des schémas abstraits qui sont bien intériorisés. Il devient alors plus facile pour les sujets de les réutiliser et des les transposer.  
	\section{Quels liens avec l'apprentissage statistique?}
		Une des buts principaux de l'apprentissage statistique et la classification de données à des fins d'automatisation. Sur des images, il s'agit souvent de créer des ``boîtes'' autour des éléments principaux et de les étiqueter avec des labels, et un certain score de confiance. Sur du texte, il s'agit souvent de déterminer la tonalité du discours (\textit{sentiment analysis}), où les faits principaux (en vue de générer de résumés). Mener à bien toutes ces tâches nécessite de construire des représentations qui se rapprochent des ``concepts'' que nous avons étudiés, et ce, à partir de données non structurées. Nous allons essayer de voir comment les concepts émergent de tels impératifs.
		\begin{figure}[H]
			\centering
			\includegraphics[width=200px]{../images/object_detection.jpg}
			\caption{Résultat d'un algorithme de détection d'objets sur une image. Chaque ``boîte'' est étiquetée avec le nom de l'objet correspondant (\href{https://upload.wikimedia.org/wikipedia/commons/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg}{source})}
		\end{figure}
		\subsection{Embedding}
			L'``\textbf{embedding}'' (ou plongement en français) consiste à traduire des données brutes en vecteurs, ou, de façon équivalente, en points dans un espace multidimensionnel. Il s'agit donc d'un moyen de représenter de façon symbolique et homogène des données. Les données brutes peuvent être des images, des échantillons sonores, des mots ou une combinaison de ces différentes sources; on parle alors d'\textit{embedding \textbf{multimodal}}. Dans ce mémoire, on se focalisera sur les données textuelles et visuelles.
			\begin{figure}[H]
				\centering
				\includegraphics[width=250px]{../images/embedding.png}
				\caption{``Plongement'' (embedding) de données dans un espace vectoriel}
			\end{figure}
			Le but principal d'un embedding est de peupler un espace par des vecteurs \textit{signifiants}. En d'autres termes, on cherche à regrouper dans le même voisinage les vecteurs correspondant à des données proches sémantiquement: par exemple, des images de voiture avec des images de voitures, des termes liés à l'hygiène avec des termes liés à l'hygiène etc. Dans un embedding, la distance sémantique se traduit donc, entre autres, par une distance au sens topologique (la norme précise à utiliser restant à déterminer). Une telle notion d'espace sémantique avait déjà été soulevée par \cite{rosch1975} : ``we can predict that items with the greatest family resemblance should fall in the center of the semantic space defined by proximity scaling of the items in a category [...] a semantics space in which the distance of items from the origin of the space is determined by their degree of family resemblance''. Nous nous proposerons dans cette section de vérifier si les intuitions soulevées et testées par les psychologues trouvent un pendant dans les espaces d'embedding.
			\subsubsection{Embedding de mots}
			Le but est d'obtenir, par apprentissage non-supervisé, une représentation vectorielle des mots. Deux grands types de méthodes concurrentes permettent d'aboutir à des embeddings textuels comme le rappellent \cite{pennington2014}:
			\begin{itemize}
				\item les méthodes \textbf{prédictives} (skip-gram, CBOW, cf. \cite{mikolov2013}) basées sur des fenêtres de mots
				\item les méthodes basées sur le décompte de \textbf{co-occurrences} de mots et sur la factorisation de matrices de co-occurrence (LSA).
			\end{itemize}
			Ces deux approches reposent sur l'idée fondamentale que des mots en présence dans les mêmes contextes doivent être proches, et doivent donc avoir des traits sémantiques en commun.\\
			
				La première implémentation de méthodes prédictives pour générer des embeddings est due à \cite{mikolov2013}. Les différents modèles sont regroupés sous le nom de Word2vec. Word2vec implémente la méthode du skip-gram et la méthode du sac de mots continu (CBOW):
				\begin{itemize}
					\item la méthode du skip-gram vise à prédire le \textbf{contexte} d'un mot;
					\item la méthode du sac de mots continus vise à prédire un \textbf{mot central} étant donné son contexte.
				\end{itemize}
				Ces deux méthodes sont très simples et ne requièrent pas un grand nombre de couches: une couche cachée suffit.	
				\begin{figure}[H]
					\centering
					\includegraphics[width=200px]{../images/cbow.png}
					\includegraphics[width=220px]{../images/skip-gram.png}
					\caption{Modèle CBOW (gauche) et skip-gram (droite)}
				\end{figure}
				On peut à première vue se demander quel est le lien entre la prédiction de mots et la création d'un espace sémantique. Le fait est que la prédiction de mots \textit{nécessite} un espace sémantique; autrement dit, les modèles prédictifs doivent apprendre cette représentation de façon implicite pour faire de meilleures prédictions. L'intérêt des méthodes prédictives pour l'embedding ne réside donc pas dans leur \textit{output}, mais dans leur couche cachée. C'est dans cette couche, et à mesure que le réseau s'entraîne, que se crée l'espace sémantique. Pour mieux illustrer ce fait, nous allons détailler l'algorithme lié à la méthode CBOW. Nous utilisons pour cela \cite{socher2016}. L'entraînement d'un modèle CBOW consiste à:
				\begin{enumerate}[label=(\roman*)]
					\item encoder en \textit{one-hot} les mots du contexte. Un encodage one-hot transforme un mot issu d'un lexique de taille $N$ en un vecteur de taille $N$, possédant une seule coordonnée à $1$ (celle que l'on a choisie pour correspondre au mot) et les autres coordonnées à $0$;
					\item \textbf{plonger les vecteurs one-hot dans l'espace d'\textit{embedding}, par changement de base (multiplication par une ``matrice d'embedding'')};
					\item calculer le barycentre (somme pondérée) de ces vecteurs dans l'espace d'embedding\footnote{c'est l'application d'un principe simplifié de compositionnalité sémantique};
					\item donner un score à ce barycentre (via une multiplication matricielle), puis de transformer ce score en vecteur de probabilités à l'aide d'un \textit{softmax} -- cette opération permet en fait un \textit{remapping} dans l'espace de départ\footnote{l'espace ``one-hot''};
					\item comparer le vecteur de probabilités avec le vecteur one-hot correspondant au mot central avéré (par exemple avec une fonction de coût de type entropie croisée);
					\item \textbf{de rétropropager l'erreur, ce qui a notamment pour effet d'optimiser la matrice d'embedding}.
				\end{enumerate}~\\
			
			
			Les modèles basés sur les co-occurrences de mots, notamment l'\textbf{analyse sémantique latente} (\cite{landauer1997,deerwester1990}), nécessitent de définir proprement la notion de co-occurrence. Deux mots co-occurrents apparaissent dans le même ``document''. Un ``document'' peut-être, comme son nom l'indique, un texte provenant d'une certaine source (par exemple, un livre est un document, un article de journal est un document, une page web est un document...). Mais par extension, on peut appeler document tout texte marqué par une continuité sémantique. À ce titre, différents chapitres ou paragraphes d'un livre pourront être considérés comme des documents. Les modèles basés sur la co-occurrence postulent en effet que des mots présents dans le même document partageront des traits sémantiques. Cette hypothèse est appelée \textbf{hypothèse distributionnelle} (\cite{erk2012}).\\
			
			La détermination des co-occurrences de mots nécessite de recenser les documents dans lesquels les mots apparaissent. On définit donc un lexique $L$ et un ensemble de documents $D$:
			\begin{eqnarray*}
				L &=& \lbrace l_1, l_2, \dots l_n \rbrace\\
				D &=& \lbrace d_1, d_2 \dots d_m \rbrace
			\end{eqnarray*}
			On suppose que les documents $d_j$ sont des listes de lexèmes (donc un lexème est susceptible d'apparaître plusieurs fois dans un document donné). On construit alors la matrice de co-occurence $M \in \mathcal{M}_{n, m}(\mathbb{R})$:
			\begin{equation*}
				\forall i, j \in [[1; n]] \times [[1; m]], \ M[i, j] = \# l_i \in d_j
			\end{equation*}
			Où $\# l_i \in d_j$ se lit ``nombre de fois où $l_i$ apparaît dans $d_j$''. À l'aide de cette matrice, on peut trouver tous les mots co-occurrents dans le document $d_j$ en regardant les composantes non nulles de la colonne $j$. On peut aussi trouver dans quels document apparaît le lexème $l_i$ en regardant les composantes non nulles de la ligne $i$. La corrélation entre deux mots $l_i$ et $l_k$ est alors donnée par M$[k;]^tM[i;]$; c'est le produit composante par composante des lignes $i$ et $k$.\\
			
			Le problème de cette matrice $M$ est qu'elle est de très grande dimension, et très \textit{sparse} (beaucoup de composantes à zéro). Il convient donc d'en trouver une approximation\footnote{en réalité, faire une telle ``approximation'' n'est pas forcément mauvais pour la qualité de l'information; en effet, cela permet de réduire le bruit, l'influence des \textit{outliers} etc.} de plus faible dimension. Un processus optimal consiste à décomposer la matrice $M$ en valeurs singulières\footnote{une décomposition en valeurs singulières est une généralisation de la diagonalisation; il s'agit de trouver une base dans laquelle la matrice s'exprime comme une matrice diagonale}, et à ``tronquer'' les trois matrices ainsi obtenues:
			\begin{equation*}
			M = U_{(n, r)} S_{(r, r)} V_{(r, m)} \sim \hat U_{(n, k)} \hat S_{(k, k)} \hat V_{(k, m)}
			\end{equation*}
			Cela permet d'avoir une représentation plus compacte des statistiques, mais aussi, de construire un espace sémantique. Comme dans le cas des méthodes prédictives, cet espace est obtenu comme un sous produit de la transformation. En effet, la matrice de départ exprime chaque mot comme une combinaison linéaire de documents ou vice versa. La matrice $S$, qui est diagonale, propose une représentation ``pure'' de ces relations dans une autre base -- celle des concepts. Chaque mot et chaque document sont alors alignés sur un concept, et les poids (valeurs singulières) de $S$ désignent l'importance des concepts. Les matrices ``de passage'' $U$ et $V$\footnote{dans le cas général ce ne sont pas des matrices de passage au sens strict, mais elles ont le même rôle} indiquent donc comment sont représentés les mots et les documents dans l'espace sémantique. La représentation des mots dans l'espace sémantique pondéré par l'importance des concept est alors:
			\begin{equation}
				E(l_i) = \hat S U[i;]
			\end{equation}
			
			Au bilan, les méthodes prédictives n'utilisent pas de façon optimale les statistiques globales des corpus, pourtant elles affichent de bonnes performances sur les tâches d'analogie. Les méthodes de décompte au contraire tirent très bien parti des statistiques des corpus, mais ont de moins bonnes performances sur les tâches d'analogie. Cela dit, les deux méthodes ne sont pas si différentes, car elles exploitent toutes deux de façon plus ou moins explicite des statistiques de co-occurrence. Des modèles comme GloVe (\cite{pennington2014}) tentent de combiner les avantages des deux approches. Nous avons utilisé GloVe pour déterminer comment seraient représentés les concepts utilisés par Rosch dans \cite{rosch1975}. Une représentation en 2D commentée est visible en Annexe (Figure \ref{fig:embedding_rosch}).
		
			\subsubsection{Embedding d'images}
				Les embeddings d'images projettent des images \footnote{à voir comme des matrices pour les images en noir et blanc, ou des tenseurs à trois dimensions pour les images en couleur} dans un espace vectoriel. Nous allons voir que, comme dans le cas des embeddings textuels, un embedding d'image est obtenu comme sous-produit d'un autre processus, le processus lié à la classification d'images. En effet, le but principal des réseaux de neurones appliqués au images et de mettre un label sur ces images; \textit{e.g.} de reconnaître un agrégat de pixels comme étant un chat. En général, les labels sont fixés à l'avance; par exemple, le dataset ImageNet, qui compte près de 14 millions d'images labellisées à la main, comporte environ 20 000 catégories. Ces catégories, ou un sous-ensemble pertinent de ces catégories\footnote{sur ImageNet, 1000 catégories sont souvent retenues}, sont utilisés lors de la phase d'apprentissage et de test de réseau de neurones. Typiquement, un réseau de neurones entraîné à classifier sur N labels produira en sortie pour chaque image qui lui est donnée un vecteur normalisé à N dimensions. Chaque composante du vecteur correspond à une catégorie, et, pour une image donnée, la valeur de cette composante correspond à la probabilité que l'image appartienne à la catégorie. Cette représentation ressemble donc à celle que nous avons introduite dans le cadre du modèle statistique des concepts (Section \ref*{concept_stat}). Un réseau bien entraîné auquel on donne une image de chat devra renvoyer un vecteur avec une composante tendant vers 1 (celle correspondant à la catégorie ``chat'') et les autres composantes avoisinant de 0.\\
				
				Cependant, ce n'est pas ce niveau de représentation qui apparaît comme le plus intéressant lorsqu'il s'agit d'embedding d'images; en effet, la dernière couche du réseau ``oublie'' (ou plutôt, agrège) un certain nombre de caractéristiques de plus bas niveau propres aux objets. La sortie du réseau de neurone n'est qu'un \textit{mapping} de l'image vers les catégories bien normées (les labels) qui lui correspondent le mieux. Pour avoir une représentation plus riche des images, il faut donc s'intéresser au \textbf{niveaux intermédiaires} du réseau. Bien sûr, les premières couches du réseau déterminent des caractéristiques d'extrêmement bas niveau (contours, formes générales...), ce n'est donc pas là qu'il convient de regarder. En fait, il suffit souvent de tronquer la dernière couche du réseau pour obtenir une représentation satisfaisante -- à la fois plus riche (plus de dimensions) et signifiante (même si les dimensions ne correspondent pas à des concepts \textit{purs}, elles correspondent à des caractéristiques relativement interprétables).
				\begin{figure}[H]
					\centering
					\includegraphics[width=300px]{../images/vgg.png}
					\caption[bla]{Représentation d'un réseau VGG\footnotemark, couche par couche (1 couche = 1 tenseur à trois dimensions). Pour obtenir un embedding sur ce genre de réseau, il suffit d'enlever la dernière couche (celle qui donne un tenseur de forme (1, 1, 1000)). On obtient alors un espace de dimension 4000 (tenseur de forme (1, 1, 4000))}
				\end{figure}
				\footnotetext{réseau crée par le Visual Geometry Group d'Oxford (\cite{simonyan2014})}
				
				Une fois de plus, un réseau bien entraîné à catégoriser dans l'espace des labels devra avoir une avant dernière couche de bonne qualité au niveau sémantique; ce qui montre que l'embedding est appris à mesure que le réseau apprend à classifier. Dans les figures présentes en Annexe (Figure \ref{fig:embedding_cat_dog} et Figure \ref{fig:good_cat}), nous avons utilisé un réseau de neurones pré-entraîné sur ImageNet avec 1000 catégories, et pour chaque image passée en input (chat ou chien), nous avons prélevé l'output du réseau au niveau de l'avant dernière couche. Nous avons ensuite réduit la dimension de ces vecteurs à 2 avec t-SNE pour pouvoir les visualiser. Nous voyons que l'espace d'embedding rend bien compte de la différence entre chats et chiens, car on peut constater une répartition bimodale des images testées. Au sein de chaque distribution, on remarque que des sous-catégories émergent : chats tigrés, noir et blanc, roux, écaille de tortue, labradors, bergers. Il est intéressant de noter que le réseau n'avait pas forcément appris à \textit{classifier} ces sous-catégories, car elles ne faisaient pas partie des labels; mais le réseau a tout de même été conduit à les \textit{reconnaître} car dans un sens elles l'aidaient à mieux catégoriser les chats en chats et les chiens en chiens. Ces sous-catégories n'auraient pas été visibles si on avait utilisé la dernière couche du réseau, car elles auraient toutes été concentrées à peu près au même endroit.
				\begin{figure}[H]
					\centering
					\includegraphics[width=150px]{../images/chihuahua_muffin.jpg}
					\caption{Une tâche difficile pour les algorithmes est de différencier les chihuahua des muffins (\href{https://medium.freecodecamp.org/chihuahua-or-muffin-my-search-for-the-best-computer-vision-api-cbda4d6b425d}{source}); pourtant, les deux concepts sont très différents l'un de l'autre... l'information visuelle suffit-elle vraiment à modéliser les concepts?}
				\end{figure}
			\subsubsection{Embedding multimodal}
				On peut reprocher aux modèles d'\textit{embedding} n'exploitant qu'un seul type de donnée de ne pas avoir beaucoup de réalité cognitive. En effet, lorsque nous somme confrontés à des instances de concepts (sous forme textuelle, ou sous forme visuelle), notre mémoire active généralement des \textbf{traces de types variés}:
				\begin{itemize}
					\item lorsque le stimulus est écrit, une image correspondant au mot est souvent convoquée;
					\item lorsque le stimulus est visuel, d'autres mots -- plus ou moins généraux, plus ou moins adéquats -- mais liés sémantiquement à l'image peuvent être convoqués.
				\end{itemize}
				Dans les deux cas, le stimulus peut également évoquer le souvenir d'une situation vécue (mémoire épisodique). L'\textit{embedding} multimodal à pour but de simuler ces phénomènes d'association, dans le but d'augmenter la précision et la pertinence de la représentation. \cite{frome2013} développent par exemple un modèle multimodal visuel et sémantique très performant sur des tâches souvent difficiles pour les réseaux de neurones:
				\begin{itemize}
					\item vocabulaire ``ouvert'': le modèle est capable de catégoriser des images avec un vocabulaire qui peut facilement être agrandi, sans surcoût dans la phase d'entraînement;
					\item \textit{zero-shot learning} : capacité de catégoriser des images faisant partir d'un concept inédit;
					\item pertinence dans l'erreur: propension des erreurs de catégorisation à ne pas être trop ``absurdes'' (\textit{i.e.} éloignées du concept cible)  
				\end{itemize}
				Le réseau se base sur deux embeddings pré-entraînés : un embedding visuel à l'état de l'art en 2013 (AlexNet), et un embedding textuel formé à l'aide du modèle skip-gram de Word2vec. L'\textit{embedding} visuel est ensuite \textit{fine-tuné} afin d'obtenir un \textit{mapping} avec l'\textit{embedding} textuel. L'architecture du réseau est donc assez proche des processus cognitifs opérants lors d'une catégorisation d'image par un humain: d'abord il s'agit de repérer les attribut importants l'image (embedding visuel), puis de faire correspondre ces attributs au mot le plus adéquat de notre lexique (embedding textuel). \\
				
				En cas d'erreur, un bon mapping textuel/visuel garantit de tomber dans le voisinage du label correct, qui s'avère être un voisinage sémantique. Cette propriété du réseau explique se ``pertinence dans l'erreur''. Dans le cas d'images inédites, le réseau est capable de catégoriser en abstrayant ou en se montrant plus spécifique en fonction des images semblables déjà catégorisées. Là encore, cette capacité vient de la qualité de l'espace sémantique qui est à même de traduire en distances les relations de similarité entre labels.
				\begin{figure}[H]
					\centering
					\includegraphics[width=300px]{../images/devise.png}
					\caption{Architecture du réseau développé par \cite{frome2013} (au centre: réseau siamois final; à gauche, composante visuelle pré-entraînée du réseau; à droite, composante textuelle pré-entraînée du réseau)}
				\end{figure}
			
		\subsection{Topologie des embeddings}
			\subsubsection{Dimensionnalité}
				Les espaces d'embedding ont généralement une assez grande dimensionnalité (entre 100 et 1000). Cela ne rend pas très commode une analyse qualitative de ces espaces. De plus, une trop grande dimensionnalité peut rendre les calculs sur l'espace (similarité, clustering...) difficilement tractables. C'est pourquoi il existe des algorithmes de réduction de la dimensionnalité:
				\begin{itemize}
					\item l'analyse en composantes principales (\textbf{PCA}), qui consiste à repérer les dimensions très corrélées de l'espace de départ, et à les ``fusionner'' par des opérations linéaires (multiplication par une matrice). Cet algorithme permet de conserver la majeure partie de l'information statistique présente dans l'espace de départ (conservation de la variance notamment). Cela fait de cet algorithme un candidat idéal pour le postprocessing.
					\item l'algorithme \textbf{t-SNE}, qui consiste à restituer au mieux dans un espace 2D ou 3D les relations de distance existant dans une espace de dimension bien supérieure. Autrement dit, les points éloignés dans l'espace multidimensionnel le seront toujours dans l'espace bidimensionnel, et de même les points proches dans l'espace multidimensionnel le seront toujours dans l'espace bidimensionnel. Contrairement à la PCA, cet algorithme est non-linéaire, il est donc surtout adapté à la visualisation.
				\end{itemize}
			\subsubsection{Similarité}
				Un embedding vectoriel bien réalisé est un espace dans lequel les entités proches géométriquement sont aussi proches sémantiquement. Mais comment au juste quantifier cette notion de similarité? Deux normes sont couramment utilisées: la similarité cosinus et la norme L2.
				\begin{eqnarray*}
					sim(u, v) &=& cos(u, v) = \frac{u.v}{||u||_2 ||v||_2} = \frac{\sum_{i = 1}^{N}u_iv_i}{\sqrt{\sum_{i = 1}^N u_i} \sqrt{\sum_{i = 1}^N v_i}}\\
					d(u, v) &=& ||v-u||_2 = \sqrt{\left(\sum_{i = 1}^N (v_i-u_i)^2\right)} 
				\end{eqnarray*}
				La première norme prend en compte l'angle formé par les deux vecteurs: plus il est petit, plus les deux vecteurs pointent vers la même direction, plus les points correspondants sont proches. La deuxième distance est une généralisation de la notion de distance classique en deux dimensions. La similarité ainsi obtenue ne rend pas simplement compte des relations de synonymie. Concernant les embeddings textuels, \cite{erk2012}, remarque que les relations sémantiques recouvrent en fait la \textbf{méronymie}, le \textit{\textbf{priming}}, l'égalité hiérarchique (nœuds frères dans un arbre), l'égalité des contextes (mots employés dans les mêmes situations). De fait, l'embedding capture tous les biais qui étaient présents dans le corpus d'entraînement, et ces biais ont des origines variées. Cela inclue également des \textbf{stéréotypes}, notamment des stéréotypes de genre qui peuvent s'avérer très marqués (\cite{bolukbasi2016}). Un exemple classique est la similarité genre-métier. D'un côté, cela prouve que l'apprentissage statistique est capable de capturer et de révéler les concepts implicites sous-tendus par les mots; mais d'un autre côté l'usage de tels algorithmes comporte bien entendu des risques en termes d'éthique.
				
				
				
			\subsubsection{Catégories}
				Dans un espace sémantique, il apparaît naturel de rechercher des groupes de données susceptibles de former des concepts. Cette tâche peut être menée à bien grâce à des algorithmes de \textit{\textbf{clustering}}, qui ont pour rôle d'associer chaque donnée à un groupe, de sorte que les données proches dans l'espace en question se retrouvent dans le même groupe, et que les données éloignées forment des groupes différents. L'algorithme de clustering les plus connu est sans doute celui des \textbf{K-centres} (\cite{lloyd1982}), qui se base d'ailleurs sur le principe des prototypes. Chaque cluster est défini par un prototype. Un point de l'espace sera associé à un cluster donné, si le prototype correspondant à ce cluster est le prototype le plus proche du point. La position des prototypes est choisie de sorte à minimiser la somme des carrés des distances entre le prototype et chacun des points du cluster. Cette intuition rejoint celle selon laquelle les prototypes sont des éléments ``centraux''\footnote{à l'aune de certaines caractéristiques, qui correspondent ici aux dimensions de l'espace} d'un cluster. Elle satisfait aussi notre propension naturelle pour la convexité et la connexité (\cite{chemla2017}).\\
				
				Il existe des généralisations très performantes de cet algorithme, notamment des modèles à base de mixtures de gaussiennes. Ces modèles rendent les frontières des clusters progressives (influence de la distribution gaussienne), ce qui fait qu'un point de l'espace aura différentes probabilités d'appartenir aux clusters présents. On retrouve alors la notion de degré d'appartenance à un concept discutée précédemment (Section \ref{concept_stat}).
				\begin{figure}[H]
					\centering
					\includegraphics[width=200px]{../images/k_means.png}
					\caption{Représentation schématique du résultat de l'algorithme des K-centres. Trois clusters sont représentés (rouge, vert, bleu). Les prototypes (marqueur diamant) sont situés au voisinage du barycentre des clusters, afin de minimiser la distance aux points du cluster.}
				\end{figure}
				
			
				
				
				Un cluster, à l'image de l'espace duquel il est extrait, est multidimensionnel. Cette propriété rend en fait les clusters très proches des concepts psychologiques dont la cohésion est assurée par un ``air de famille'' : deux éléments d'un cluster ont un faisceau d'attributs en commun (autrement dit leur projection sur certaines dimensions sont très proches), mais n'ont pas nécessairement \textit{tous} leurs attributs en commun. En termes mathématiques, cela se traduit par le fait que les clusters de forment jamais d'hyperplan au sein de l'espace d'embedding. Quelle que soit la méthode de clustering\footnote{certaines méthodes non discutées ici, comme la propagation d'affinité ou la méthode par densité DBSCCAN, se basent sur une idée de voisinage et de transmission. Il est par ailleurs intéressant de noter que ces mêmes idées sont utilisées dans des paradigmes expérimentaux comme celui de la maladie infectieuse pour déterminer les concepts humains.}, le ``prototype'' est souvent défini comme le barycentre du cluster (ou la donnée réelle la plus proche du barycentre théorique):
				\begin{equation*}
					proto(C) = argmin_{x \in C} d\left(x, \frac{1}{|C|}\sum_{x' \in C}x' \right)
				\end{equation*}
				Où $d$ est une certaine distance (souvent, la norme L2 ou la similarité cosinus).\\
				
				Par ailleurs, il est courant d'évaluer la qualité d'un clustering à l'aide de deux critère principaux:
				\begin{itemize}
					\item la cohésion intra-cluster (\textbf{compacité}), qui mesure à quel point les éléments d'un cluster sont concentrés autour du barycentre du cluster. Une mesure typique est la somme des carré des distances entre les points et le barycentre;
					\item la séparabilité inter-cluster (\textbf{isolation}), qui mesure à quel point les clusters sont éloignés les uns des autres. Une mesure typique est la distance moyenne entre barycentres.
				\end{itemize}
				Ces mesures sont encore une fois cohérentes avec la vision de \cite{rosch1975}, selon laquelle les prototypes doivent être assez proches d'un maximum d'éléments du concept, et assez loin des autres prototypes.\\
				

			\subsubsection{Relations}
				Si les points de l'espace d'\textit{embedding} désignent des entités, il apparaît naturel de définir les relations (``flèches'') entre ces points comme des vecteurs. Par exemple, un vecteur pointant d'une entité ``capitale'' vers une entité ``pays'', pourra être vu, sous certaines conditions liées au contexte, comme la relation ``est la capitale de''. Il convient alors de se demander si ces relations sont bien constantes dans l'espace; autrement dit, si deux couples d'entités liées par la même relation $R$ sont aussi liés par le même vecteur de translation:
				\begin{equation*}
				\exists?V, \ \forall (x, y), \ xRy \iff  y = x+V
				\end{equation*}
				Si tel est le cas, il devient possible de répondre à des problèmes d'analogie proportionnelle dans l'espace, à l'aide d'opération arithmétiques simples:
				\begin{equation*}
				a:b::c:d \iff d = argmax_{d\in V}sim(d, c-a+b)
				\end{equation*}
				Cette équation nous dit que l'objet $d$ sera obtenu en reportant le vecteur de translation de a vers b sur $d$. À noter que dans certains cas, il peut être pertinent de relaxer la condition d'égalité de normes des vecteurs, pour ne garder qu'une égalité de directions.
				\begin{figure}[H]
					\centering
					\includegraphics[width=200px]{../images/analogy_vec.png}
					\caption{Résolution vectorielle d'analogie; le point théorique $d'$ est ici \textit{remappé} vers le point $d$, son plus proche voisin qui correspond à une donnée réelle (mot, image etc.)}
				\end{figure}
				L'analogie se traduit donc par le report d'un vecteur. Cette opération incarne bien la propriété de parallélisme des analogies mentionnée en Section \ref{analogy_cog}; en effet, le champ de vecteurs représentant une relation définit des relations univoques et systématiques (colinéarité). Il paraît également envisageable de définir des mappings plus complexes, faisant intervenir plusieurs relations et plusieurs objets. Mais il n'est pas certain que l'espace soit à même de conserver ces relations d'ordre supérieur.
				
\section*{Conclusion générale}
\addcontentsline{toc}{section}{Conclusion générale}
	Notre ``conception des concepts'' a beaucoup évolué depuis les années 70, nous faisant passer d'un modèle idéalisé des concepts (vus comme de purs ensembles), à un modèle plus écologique, plus flexible, et plus nuancé, à base de catégories probabilistes aux conditions plus floues. Ce genre de modèle rend mieux compte de notre capacité et de notre facilité à catégoriser des objets: les objets les plus prototypiques d'une classe poseront moins de problèmes que les objets ``borderline''. Cela dit, une telle conception pose le problème de la poule et de l'œuf: les prototypes découlent-ils des concepts? Ou bien les concepts sont-ils construits en fonction des prototypes? Si la première explication est vraie, alors le prototype peut raisonnablement être vu comme le ``point-milieu'' de l'ensemble des éléments appartenant au concept, suffisamment distinctif des autres prototypes. Si la seconde explication s'avère être la bonne, alors un concept est défini comme le voisinage d'un prototype.\\
	S'est ensuite posée la question de l'analogie entre concepts. Une analogie est un moyen de mettre en relation des schémas faisant intervenir des objets et des relations. Les analogies permettent de résoudre des problèmes inédits, sur la base de problèmes déjà rencontrés et suffisamment similaires. Elles permettent aussi la généralisation et l'apprentissage de catégories abstraites dépassant les différences de surface. Mais là encore se pose le problème de la relation entre analogie et concepts: l'analogie est-elle définie à partir des concepts par substitution d'objets (caractères de surface)? Ou bien, les concepts que nous croyons connaître découlent-ils d'analogies multiples générées à partir d'un jeu restreint des concepts fondamentaux?\\
	
	Il faut avouer que la perspective informatique s'intéresse peut à ses questions ontologiques, dans la mesure où l'approche des concept s'intègre dans une démarche que l'on pourrait qualifier de \textit{reverse-engineering}. À partir d'une ensemble fini d'instances concrètes (les données), les algorithmes d'apprentissage cherchent à reconstruire l'espace conceptuel le plus probable. Il ne s'agit donc pas de savoir ce qui génère quoi, mais simplement de déterminer ce qui \textit{est}. Pour cela, un certain nombre d'intuitions vérifiées expérimentalement sont formalisées mathématiquement: équivalence entre proximité géométrique et proximité sémantique, entre typicalité et centralité, entre relation et translation. Ces méthodes fonctionnent bien sur des tâches basiques telles que la résolution d'analogies proportionnelles ou les tâches de paraphrase. Mais il n'est pas certain que les modèles aient pu encoder des propriétés de plus haut niveau, comme les analogies d'ordre supérieur, le versant pragmatique de certains concepts ou la polysémie. Le problème a sans doute deux sources. D'une part, les données en entrée ne reflètent que partiellement la réalité psychologique des concepts (comme on a pu le voir, des entrées multimodales rendent cela un peu moins vrai); d'un autre côté, les algorithmes qui traitent l'espace conceptuel comme le simple sous-produit d'une autre tâche ne rendent pas forcément compte du raisonnement humain. Par exemple, est-il bien vrai que notre connaissance du sens des mots se développe à mesure que nous développons notre capacité à prévoir le mot suivant d'une phrase? Il est permis d'en douter.\\
	
	Pour aller plus loin, il serait intéressant de comparer plus explicitement les résultats d'un algorithme d'apprentissage avec les modes de représentation humains. À cette fin, nous pourrions envisager deux tâches expérimentales:
	\begin{itemize}
		\item conservation des distances comme modèle de l'analogie:
		on demande à des participants de placer des photos d'objets sur un support. Les objets forment des paires liées par une relation donnée. On vérifie que les participants ``translatent'' effectivement les paires d'images.
		\item barycentre comme modèle du prototype: on calcule un embedding visuel, on obtient un clustering de cet espace, et pour chaque cluster on relève les images centrales et borderline. On demande à de sujets de noter la typicalité de ces images.
	\end{itemize}

\newpage
\nocite{*}
\newpage
\defbibheading{main}{\textbf{Supports principaux}}
\defbibheading{minor}{\textbf{Supports secondaires}}
\section*{Références}
\addcontentsline{toc}{section}{Références}
\printbibliography[heading=main, keyword=main]
\printbibliography[heading=minor, keyword=minor]				
\newpage
\section*{Annexes}
\addcontentsline{toc}{section}{Annexes}
	\begin{figure}[H]
		\centering
		\includegraphics[width=420px]{../images/word_embedding.png}
		\caption{\textit{Embedding} de mots obtenu avec GloVe (6B, 300 dimensions) après PCA (2 dimensions), pour 3 des concepts testés par \cite{rosch1975}. Les points de couleur rouge sont des points censés être prototypiques; les points jaunes sont des points \textit{borderline}. On constate que les trois concepts forment des clusters assez visibles. Par contre, les éléments prototypiques de l'expérience de Rosch ne se retrouvent pas nécessairement au centre des clusters observés.}
		\label{fig:embedding_rosch}
	\end{figure}
	\begin{figure}[H]
		\centering
		\includegraphics[width=420px]{../images/tsne_vgg.png}
		\caption{Embedding obtenu à partir d'un réseau VGG de 16 couches pré-entraîné sur ImageNet. Projection par t-SNE dans un espace à deux dimensions. Les images testées par le réseau étaient des images de chien ou de chat. 400 images sont représentées ici.}
		\label{fig:embedding_cat_dog}
	\end{figure}
	\begin{figure}[H]
		\centering
		\begin{subfigure}[b]{.45\textwidth}
			\centering
			\includegraphics[width=\textwidth]{../images/most-dog.png}
			\caption{Chiens les plus proches du prototype}
		\end{subfigure}
		\begin{subfigure}[b]{.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../images/less-dog.png}
		\caption{Chiens les plus éloignés du prototype}
	\end{subfigure}

	\begin{subfigure}[b]{.45\textwidth}
	\centering
	\includegraphics[width=\textwidth]{../images/most-cat.png}
	\caption{Chats les plus proches du prototype}
	\end{subfigure}
	\begin{subfigure}[b]{.45\textwidth}
	\centering
	\includegraphics[width=\textwidth]{../images/less-cat.png}
	\caption{Chats les plus éloignés du prototype}
	\end{subfigure}
	\caption{Images ``prototype'' et ``borderline'' associées aux clusters ``chat'' et ``chien''. Les clusters ont préalablement été déterminés en utilisant un algorithme des K-centres. Pour chaque cluster (chat ou chien), les images ``prototypes'' sont les images du cluster les plus proches (similarité cosinus) du K-centre du cluster. Les images ``borderline'' sont les images du cluster les moins similaires avec le K-centre. On constate notamment que les prototypes de chat et de chien sont des variétés ``sans race''. Les chats et chiens borderline le sont du fait de la qualité de la photo (animaux en cage, ``encadrés'', ou ``parasités'' par un humain), ou du fait de leur race particulière (caniche, siamois...)}
	\label{fig:good_cat}
	\end{figure}
		
		


\end{document}
